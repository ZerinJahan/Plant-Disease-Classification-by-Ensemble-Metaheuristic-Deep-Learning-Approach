{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "f010f7af-afb6-4e8b-8b5c-1430c38d75d7",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import time\n",
    "import torch\n",
    "import torchvision\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "import torchvision.transforms as transforms\n",
    "from torch.utils.data import DataLoader\n",
    "from torchvision.datasets import ImageFolder\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.metrics import classification_report, confusion_matrix, roc_curve, auc\n",
    "import seaborn as sns\n",
    "from sklearn.utils.class_weight import compute_class_weight\n",
    "import torch.nn.functional as F"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "797641f6-5225-431b-b6ad-ced1a5f91e27",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CUDA Available: True\n",
      "GPU Count: 1\n",
      "GPU Name: NVIDIA GeForce RTX 4070 Laptop GPU\n",
      "Using device: cuda\n",
      "Using device: cuda:0\n",
      "GPU Name: NVIDIA GeForce RTX 4070 Laptop GPU\n",
      "✅ Tensor successfully moved to: cuda:0\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "print(\"CUDA Available:\", torch.cuda.is_available())\n",
    "print(\"GPU Count:\", torch.cuda.device_count())\n",
    "print(\"GPU Name:\", torch.cuda.get_device_name(0) if torch.cuda.is_available() else \"No GPU detected\")\n",
    "\n",
    "# Check GPU\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "print(f\"Using device: {device}\")\n",
    "\n",
    "# Force NVIDIA GPU (GPU 0)\n",
    "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
    "\n",
    "# Verify GPU selection\n",
    "print(f\"Using device: {device}\")\n",
    "print(\"GPU Name:\", torch.cuda.get_device_name(device))\n",
    "\n",
    "# Create a random tensor and move it to the selected GPU\n",
    "x = torch.randn(1000, 1000).to(device)\n",
    "print(\"✅ Tensor successfully moved to:\", x.device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "5c01fb45-fe2f-4f7f-bb53-2d229e9facf4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Directories\n",
    "data_dir = \"E:/Works/12. Plant Diseases Classification/Datasets/Work_Dataset\"\n",
    "train_dir = os.path.join(data_dir, \"train\")\n",
    "valid_dir = os.path.join(data_dir, \"valid\")\n",
    "test_dir = os.path.join(data_dir, \"test\")\n",
    "external_test_dir = os.path.join(data_dir, \"External_testing_dataset\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "7db11838-d719-441f-a298-dc7b8d5b00e7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Hyperparameters\n",
    "batch_size = 16\n",
    "num_epochs = 50\n",
    "learning_rate = 0.001\n",
    "img_size = 224\n",
    "weight_decay = 1e-4\n",
    "patience = 5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "f618a0ee-6893-4310-b3ce-8171718657ad",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Transformations\n",
    "train_transforms = transforms.Compose([\n",
    "    transforms.RandomResizedCrop(img_size, scale=(0.8, 1.0)),\n",
    "    transforms.ColorJitter(brightness=0.2, contrast=0.2, saturation=0.2, hue=0.1),\n",
    "    transforms.RandomHorizontalFlip(),\n",
    "    transforms.RandomRotation(15),\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize([0.485, 0.456, 0.406], [0.229, 0.224, 0.225])\n",
    "])\n",
    "\n",
    "valid_test_transforms = transforms.Compose([\n",
    "    transforms.Resize((img_size, img_size)),\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize([0.485, 0.456, 0.406], [0.229, 0.224, 0.225])\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "3dc4a736-607e-4886-83c8-f0f75bc16a66",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load Data\n",
    "train_dataset = ImageFolder(train_dir, transform=train_transforms)\n",
    "valid_dataset = ImageFolder(valid_dir, transform=valid_test_transforms)\n",
    "test_dataset = ImageFolder(test_dir, transform=valid_test_transforms)\n",
    "external_test_dataset = ImageFolder(external_test_dir, transform=valid_test_transforms)\n",
    "\n",
    "train_loader = DataLoader(train_dataset, batch_size=batch_size, shuffle=True)\n",
    "valid_loader = DataLoader(valid_dataset, batch_size=batch_size, shuffle=False)\n",
    "test_loader = DataLoader(test_dataset, batch_size=batch_size, shuffle=False)\n",
    "external_test_loader = DataLoader(external_test_dataset, batch_size=batch_size, shuffle=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "cca767c0-e25b-470f-a384-d641c382c262",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Classes: ['A_blk_rot_f', 'A_blk_spot', 'A_e_canker', 'A_gl_lf_spot', 'A_healthy_f', 'A_healthy_l', 'A_m_virus', 'Av_alg_lf_spot', 'Av_br_canker', 'Av_healthy_l', 'G_blk_spot_c', 'G_healthy_c', 'Kf_bac_canker', 'Kf_healthy_l', 'P_canker', 'P_fr_blight', 'P_healthy_f', 'P_healthy_l', 'P_s_pit', 'P_scab']\n"
     ]
    }
   ],
   "source": [
    "# Class Names\n",
    "class_names = train_dataset.classes\n",
    "num_classes = len(class_names)\n",
    "print(f\"Classes: {class_names}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "9b3c7f08-f494-456d-a52c-22d2913cd30c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Compute Class Weights\n",
    "labels = np.array(train_dataset.targets)\n",
    "class_weights = compute_class_weight(class_weight=\"balanced\", classes=np.unique(labels), y=labels)\n",
    "class_weights = torch.tensor(class_weights, dtype=torch.float).to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "a1c7a842-b132-4a4a-9389-3f3b9624c8d1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define Focal Loss\n",
    "class FocalLoss(nn.Module):\n",
    "    def __init__(self, alpha=None, gamma=2.0, reduction='mean'):\n",
    "        super(FocalLoss, self).__init__()\n",
    "        self.alpha = alpha  # Class weights\n",
    "        self.gamma = gamma  # Focusing parameter\n",
    "        self.reduction = reduction\n",
    "\n",
    "    def forward(self, inputs, targets):\n",
    "        ce_loss = F.cross_entropy(inputs, targets, reduction=\"none\", weight=self.alpha)\n",
    "        pt = torch.exp(-ce_loss)  # Probabilities of correct class\n",
    "        focal_loss = ((1 - pt) ** self.gamma) * ce_loss  # Focal loss formula\n",
    "\n",
    "        if self.reduction == 'mean':\n",
    "            return focal_loss.mean()\n",
    "        elif self.reduction == 'sum':\n",
    "            return focal_loss.sum()\n",
    "        else:\n",
    "            return focal_loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "4373f619-262c-4b2d-a473-46a7975c6d01",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Temperature Scaling Function\n",
    "class TemperatureScaling(nn.Module):\n",
    "    def __init__(self, init_temp=1.5):\n",
    "        super(TemperatureScaling, self).__init__()\n",
    "        self.temperature = nn.Parameter(torch.tensor(init_temp))\n",
    "\n",
    "    def forward(self, logits):\n",
    "        return logits / self.temperature"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "3e922749-bf51-4592-8ec0-a62fe540d794",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "E:\\Works\\12. Plant Diseases Classification\\venv\\lib\\site-packages\\torch\\functional.py:534: UserWarning: torch.meshgrid: in an upcoming release, it will be required to pass the indexing argument. (Triggered internally at C:\\actions-runner\\_work\\pytorch\\pytorch\\builder\\windows\\pytorch\\aten\\src\\ATen\\native\\TensorShape.cpp:3596.)\n",
      "  return _VF.meshgrid(tensors, **kwargs)  # type: ignore[attr-defined]\n"
     ]
    }
   ],
   "source": [
    "# Model Selection\n",
    "models = {\n",
    "    \"ConvNeXt-Tiny\": torchvision.models.convnext_tiny(weights=torchvision.models.ConvNeXt_Tiny_Weights.IMAGENET1K_V1),\n",
    "    \"EfficientNetV2\": torchvision.models.efficientnet_v2_s(weights=\"IMAGENET1K_V1\"),\n",
    "    \"RegNetY-8GF\": torchvision.models.regnet_y_8gf(weights=\"IMAGENET1K_V1\"),\n",
    "    \"MaxViT\": torchvision.models.maxvit_t(weights=\"IMAGENET1K_V1\"),\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "0933a6b1-988f-4327-86c2-3129bfcc3c16",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Modify models for classification\n",
    "for name, model in models.items():\n",
    "    if \"convnext\" in name.lower():\n",
    "        model.classifier[2] = nn.Linear(model.classifier[2].in_features, num_classes)\n",
    "    elif \"efficientnet\" in name.lower():\n",
    "        in_features = model.classifier[-1].in_features  \n",
    "        model.classifier[-1] = nn.Linear(in_features, num_classes)\n",
    "    elif \"regnet\" in name.lower():\n",
    "        model.fc = nn.Linear(model.fc.in_features, num_classes)\n",
    "    elif \"maxvit\" in name.lower():\n",
    "        in_features = model.classifier[-1].in_features\n",
    "        model.classifier[-1] = nn.Linear(in_features, num_classes)\n",
    "\n",
    "    # Add Temperature Scaling\n",
    "    model.temperature_scaling = TemperatureScaling()\n",
    "    \n",
    "    model.to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "a61b194a-92ce-456c-aa33-01e98905b663",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Loss Function: Choose between Class Weighted Loss or Focal Loss\n",
    "use_focal_loss = True  # Set to False to use standard class-weighted cross-entropy\n",
    "\n",
    "if use_focal_loss:\n",
    "    criterion = FocalLoss(alpha=class_weights)\n",
    "else:\n",
    "    criterion = nn.CrossEntropyLoss(weight=class_weights)\n",
    "\n",
    "# Optimizers with Weight Decay\n",
    "optimizers = {name: optim.Adam(model.parameters(), lr=learning_rate, weight_decay=weight_decay) \n",
    "              for name, model in models.items()}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "90eb62cd-4512-43ef-a748-ad6838ebf667",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Train Function\n",
    "def train_model(model, optimizer, train_loader, valid_loader, num_epochs, device):\n",
    "    history = {\"train_loss\": [], \"train_acc\": [], \"valid_loss\": [], \"valid_acc\": []}\n",
    "    start_time = time.time()\n",
    "    \n",
    "    scheduler = optim.lr_scheduler.ReduceLROnPlateau(optimizer, mode='min', factor=0.5, patience=2, verbose=True)\n",
    "    best_val_loss = float(\"inf\")\n",
    "    epochs_without_improvement = 0\n",
    "    criterion = nn.CrossEntropyLoss(weight=class_weights)  # Use computed class weights\n",
    "\n",
    "    for epoch in range(num_epochs):\n",
    "        model.train()\n",
    "        running_loss, correct, total = 0.0, 0, 0\n",
    "\n",
    "        for images, labels in train_loader:\n",
    "            images, labels = images.to(device), labels.to(device)\n",
    "            optimizer.zero_grad()\n",
    "            outputs = model(images)\n",
    "            outputs = model.temperature_scaling(outputs)  # Apply temperature scaling\n",
    "            loss = criterion(outputs, labels)\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "\n",
    "            running_loss += loss.item()\n",
    "            _, preds = torch.max(outputs, 1)\n",
    "            correct += (preds == labels).sum().item()\n",
    "            total += labels.size(0)\n",
    "\n",
    "        train_loss = running_loss / len(train_loader)\n",
    "        train_acc = correct / total\n",
    "\n",
    "        # Validation\n",
    "        model.eval()\n",
    "        val_loss, correct, total = 0.0, 0, 0\n",
    "        with torch.no_grad():\n",
    "            for images, labels in valid_loader:\n",
    "                images, labels = images.to(device), labels.to(device)\n",
    "                outputs = model(images)\n",
    "                outputs = model.temperature_scaling(outputs)  # Apply temperature scaling\n",
    "                loss = criterion(outputs, labels)\n",
    "\n",
    "                val_loss += loss.item()\n",
    "                _, preds = torch.max(outputs, 1)\n",
    "                correct += (preds == labels).sum().item()\n",
    "                total += labels.size(0)\n",
    "\n",
    "        val_loss /= len(valid_loader)\n",
    "        val_acc = correct / total\n",
    "\n",
    "        history[\"train_loss\"].append(train_loss)\n",
    "        history[\"train_acc\"].append(train_acc)\n",
    "        history[\"valid_loss\"].append(val_loss)\n",
    "        history[\"valid_acc\"].append(val_acc)\n",
    "\n",
    "        print(f\"Epoch {epoch+1}/{num_epochs} - Train Loss: {train_loss:.4f}, Train Acc: {train_acc:.4f}, Val Loss: {val_loss:.4f}, Val Acc: {val_acc:.4f}\")\n",
    "\n",
    "        scheduler.step(val_loss)\n",
    "        \n",
    "        if val_loss < best_val_loss:\n",
    "            best_val_loss = val_loss\n",
    "            epochs_without_improvement = 0\n",
    "        else:\n",
    "            epochs_without_improvement += 1\n",
    "            if epochs_without_improvement >= patience:\n",
    "                print(\"Early stopping triggered.\")\n",
    "                break\n",
    "\n",
    "    total_time = time.time() - start_time\n",
    "    return history, total_time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "a37670e5-c7fb-4526-8106-bbf91426e52a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Training ConvNeXt-Tiny...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "E:\\Works\\12. Plant Diseases Classification\\venv\\lib\\site-packages\\torch\\optim\\lr_scheduler.py:62: UserWarning: The verbose parameter is deprecated. Please use get_last_lr() to access the learning rate.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/50 - Train Loss: 2.9416, Train Acc: 0.0781, Val Loss: 2.6280, Val Acc: 0.1135\n",
      "Epoch 2/50 - Train Loss: 2.4985, Train Acc: 0.1748, Val Loss: 2.0951, Val Acc: 0.3233\n",
      "Epoch 3/50 - Train Loss: 2.1250, Train Acc: 0.2529, Val Loss: 1.9784, Val Acc: 0.3261\n",
      "Epoch 4/50 - Train Loss: 1.8958, Train Acc: 0.3277, Val Loss: 1.8258, Val Acc: 0.3448\n",
      "Epoch 5/50 - Train Loss: 1.8000, Train Acc: 0.3713, Val Loss: 1.7632, Val Acc: 0.3606\n",
      "Epoch 6/50 - Train Loss: 1.5770, Train Acc: 0.4408, Val Loss: 1.5369, Val Acc: 0.4626\n",
      "Epoch 7/50 - Train Loss: 1.5364, Train Acc: 0.4638, Val Loss: 1.5312, Val Acc: 0.4626\n",
      "Epoch 8/50 - Train Loss: 1.4269, Train Acc: 0.4844, Val Loss: 1.3547, Val Acc: 0.5115\n",
      "Epoch 9/50 - Train Loss: 1.4093, Train Acc: 0.4877, Val Loss: 1.3685, Val Acc: 0.5057\n",
      "Epoch 10/50 - Train Loss: 1.3187, Train Acc: 0.5243, Val Loss: 1.4318, Val Acc: 0.5129\n",
      "Epoch 11/50 - Train Loss: 1.2914, Train Acc: 0.5374, Val Loss: 1.4892, Val Acc: 0.4799\n",
      "Epoch 12/50 - Train Loss: 1.1115, Train Acc: 0.5970, Val Loss: 1.2935, Val Acc: 0.5589\n",
      "Epoch 13/50 - Train Loss: 1.0907, Train Acc: 0.6118, Val Loss: 1.3080, Val Acc: 0.5603\n",
      "Epoch 14/50 - Train Loss: 1.0287, Train Acc: 0.6377, Val Loss: 1.2674, Val Acc: 0.5647\n",
      "Epoch 15/50 - Train Loss: 1.0171, Train Acc: 0.6332, Val Loss: 1.1977, Val Acc: 0.5905\n",
      "Epoch 16/50 - Train Loss: 1.0021, Train Acc: 0.6501, Val Loss: 1.2246, Val Acc: 0.5991\n",
      "Epoch 17/50 - Train Loss: 0.9662, Train Acc: 0.6600, Val Loss: 1.1002, Val Acc: 0.6365\n",
      "Epoch 18/50 - Train Loss: 0.9349, Train Acc: 0.6674, Val Loss: 1.1041, Val Acc: 0.6293\n",
      "Epoch 19/50 - Train Loss: 0.8751, Train Acc: 0.6801, Val Loss: 1.1278, Val Acc: 0.6092\n",
      "Epoch 20/50 - Train Loss: 0.8704, Train Acc: 0.6768, Val Loss: 1.1335, Val Acc: 0.6494\n",
      "Epoch 21/50 - Train Loss: 0.7907, Train Acc: 0.7188, Val Loss: 1.0390, Val Acc: 0.6422\n",
      "Epoch 22/50 - Train Loss: 0.7449, Train Acc: 0.7356, Val Loss: 0.9721, Val Acc: 0.6652\n",
      "Epoch 23/50 - Train Loss: 0.7380, Train Acc: 0.7348, Val Loss: 1.0206, Val Acc: 0.6853\n",
      "Epoch 24/50 - Train Loss: 0.6894, Train Acc: 0.7512, Val Loss: 1.0032, Val Acc: 0.6810\n",
      "Epoch 25/50 - Train Loss: 0.6941, Train Acc: 0.7463, Val Loss: 1.0081, Val Acc: 0.6853\n",
      "Epoch 26/50 - Train Loss: 0.6243, Train Acc: 0.7821, Val Loss: 0.9074, Val Acc: 0.6968\n",
      "Epoch 27/50 - Train Loss: 0.6185, Train Acc: 0.7788, Val Loss: 0.9316, Val Acc: 0.6853\n",
      "Epoch 28/50 - Train Loss: 0.5899, Train Acc: 0.7800, Val Loss: 0.9821, Val Acc: 0.6968\n",
      "Epoch 29/50 - Train Loss: 0.5741, Train Acc: 0.7858, Val Loss: 0.9140, Val Acc: 0.7040\n",
      "Epoch 30/50 - Train Loss: 0.5585, Train Acc: 0.8072, Val Loss: 0.9149, Val Acc: 0.7069\n",
      "Epoch 31/50 - Train Loss: 0.5399, Train Acc: 0.7969, Val Loss: 0.9067, Val Acc: 0.7141\n",
      "Epoch 32/50 - Train Loss: 0.5298, Train Acc: 0.8072, Val Loss: 0.9367, Val Acc: 0.7040\n",
      "Epoch 33/50 - Train Loss: 0.5285, Train Acc: 0.8150, Val Loss: 0.8735, Val Acc: 0.7112\n",
      "Epoch 34/50 - Train Loss: 0.5136, Train Acc: 0.8236, Val Loss: 0.8844, Val Acc: 0.7198\n",
      "Epoch 35/50 - Train Loss: 0.4862, Train Acc: 0.8183, Val Loss: 0.8708, Val Acc: 0.7227\n",
      "Epoch 36/50 - Train Loss: 0.5218, Train Acc: 0.8117, Val Loss: 0.8667, Val Acc: 0.7112\n",
      "Epoch 37/50 - Train Loss: 0.5004, Train Acc: 0.8203, Val Loss: 0.8844, Val Acc: 0.7213\n",
      "Epoch 38/50 - Train Loss: 0.4768, Train Acc: 0.8326, Val Loss: 0.8822, Val Acc: 0.7227\n",
      "Epoch 39/50 - Train Loss: 0.5006, Train Acc: 0.8187, Val Loss: 0.9189, Val Acc: 0.7040\n",
      "Epoch 40/50 - Train Loss: 0.4722, Train Acc: 0.8224, Val Loss: 0.8984, Val Acc: 0.7155\n",
      "Epoch 41/50 - Train Loss: 0.4621, Train Acc: 0.8294, Val Loss: 0.8857, Val Acc: 0.7170\n",
      "Early stopping triggered.\n",
      "\n",
      "Training EfficientNetV2...\n",
      "Epoch 1/50 - Train Loss: 1.5739, Train Acc: 0.5271, Val Loss: 1.1181, Val Acc: 0.6624\n",
      "Epoch 2/50 - Train Loss: 0.9515, Train Acc: 0.6949, Val Loss: 0.8501, Val Acc: 0.7126\n",
      "Epoch 3/50 - Train Loss: 0.6410, Train Acc: 0.7993, Val Loss: 0.5290, Val Acc: 0.8391\n",
      "Epoch 4/50 - Train Loss: 0.5807, Train Acc: 0.8104, Val Loss: 0.6992, Val Acc: 0.7859\n",
      "Epoch 5/50 - Train Loss: 0.5120, Train Acc: 0.8359, Val Loss: 0.5621, Val Acc: 0.8290\n",
      "Epoch 6/50 - Train Loss: 0.4492, Train Acc: 0.8557, Val Loss: 0.4739, Val Acc: 0.8448\n",
      "Epoch 7/50 - Train Loss: 0.3910, Train Acc: 0.8758, Val Loss: 0.4990, Val Acc: 0.8448\n",
      "Epoch 8/50 - Train Loss: 0.3625, Train Acc: 0.8840, Val Loss: 0.5887, Val Acc: 0.8319\n",
      "Epoch 9/50 - Train Loss: 0.3449, Train Acc: 0.8886, Val Loss: 0.5256, Val Acc: 0.8362\n",
      "Epoch 10/50 - Train Loss: 0.1949, Train Acc: 0.9330, Val Loss: 0.3576, Val Acc: 0.8966\n",
      "Epoch 11/50 - Train Loss: 0.1227, Train Acc: 0.9593, Val Loss: 0.3056, Val Acc: 0.9095\n",
      "Epoch 12/50 - Train Loss: 0.1032, Train Acc: 0.9638, Val Loss: 0.4074, Val Acc: 0.8951\n",
      "Epoch 13/50 - Train Loss: 0.1501, Train Acc: 0.9498, Val Loss: 0.3475, Val Acc: 0.8994\n",
      "Epoch 14/50 - Train Loss: 0.1520, Train Acc: 0.9490, Val Loss: 0.3984, Val Acc: 0.8980\n",
      "Epoch 15/50 - Train Loss: 0.0919, Train Acc: 0.9696, Val Loss: 0.3162, Val Acc: 0.9210\n",
      "Epoch 16/50 - Train Loss: 0.0680, Train Acc: 0.9807, Val Loss: 0.3164, Val Acc: 0.9224\n",
      "Early stopping triggered.\n",
      "\n",
      "Training RegNetY-8GF...\n",
      "Epoch 1/50 - Train Loss: 1.5658, Train Acc: 0.5226, Val Loss: 1.1761, Val Acc: 0.6379\n",
      "Epoch 2/50 - Train Loss: 0.8938, Train Acc: 0.7122, Val Loss: 1.2060, Val Acc: 0.6509\n",
      "Epoch 3/50 - Train Loss: 0.7476, Train Acc: 0.7578, Val Loss: 0.9339, Val Acc: 0.6968\n",
      "Epoch 4/50 - Train Loss: 0.6300, Train Acc: 0.7965, Val Loss: 0.7619, Val Acc: 0.7529\n",
      "Epoch 5/50 - Train Loss: 0.5355, Train Acc: 0.8187, Val Loss: 0.6279, Val Acc: 0.8132\n",
      "Epoch 6/50 - Train Loss: 0.4920, Train Acc: 0.8376, Val Loss: 0.7697, Val Acc: 0.7744\n",
      "Epoch 7/50 - Train Loss: 0.4576, Train Acc: 0.8495, Val Loss: 0.6594, Val Acc: 0.8032\n",
      "Epoch 8/50 - Train Loss: 0.4220, Train Acc: 0.8664, Val Loss: 0.5874, Val Acc: 0.8103\n",
      "Epoch 9/50 - Train Loss: 0.4183, Train Acc: 0.8594, Val Loss: 0.8676, Val Acc: 0.7902\n",
      "Epoch 10/50 - Train Loss: 0.3285, Train Acc: 0.8951, Val Loss: 0.5729, Val Acc: 0.8247\n",
      "Epoch 11/50 - Train Loss: 0.3874, Train Acc: 0.8692, Val Loss: 0.6391, Val Acc: 0.8175\n",
      "Epoch 12/50 - Train Loss: 0.3124, Train Acc: 0.8980, Val Loss: 0.5196, Val Acc: 0.8621\n",
      "Epoch 13/50 - Train Loss: 0.3727, Train Acc: 0.8754, Val Loss: 0.5845, Val Acc: 0.8534\n",
      "Epoch 14/50 - Train Loss: 0.2963, Train Acc: 0.9054, Val Loss: 0.7204, Val Acc: 0.8147\n",
      "Epoch 15/50 - Train Loss: 0.3099, Train Acc: 0.8993, Val Loss: 0.5868, Val Acc: 0.8463\n",
      "Epoch 16/50 - Train Loss: 0.1540, Train Acc: 0.9552, Val Loss: 0.4096, Val Acc: 0.8822\n",
      "Epoch 17/50 - Train Loss: 0.1167, Train Acc: 0.9655, Val Loss: 0.4414, Val Acc: 0.8865\n",
      "Epoch 18/50 - Train Loss: 0.1103, Train Acc: 0.9667, Val Loss: 0.3983, Val Acc: 0.9066\n",
      "Epoch 19/50 - Train Loss: 0.0804, Train Acc: 0.9741, Val Loss: 0.3937, Val Acc: 0.9066\n",
      "Epoch 20/50 - Train Loss: 0.0950, Train Acc: 0.9704, Val Loss: 0.4322, Val Acc: 0.8937\n",
      "Epoch 21/50 - Train Loss: 0.1302, Train Acc: 0.9646, Val Loss: 0.4337, Val Acc: 0.8922\n",
      "Epoch 22/50 - Train Loss: 0.1306, Train Acc: 0.9576, Val Loss: 0.4199, Val Acc: 0.8937\n",
      "Epoch 23/50 - Train Loss: 0.0749, Train Acc: 0.9778, Val Loss: 0.3211, Val Acc: 0.9239\n",
      "Epoch 24/50 - Train Loss: 0.0498, Train Acc: 0.9868, Val Loss: 0.4353, Val Acc: 0.9009\n",
      "Epoch 25/50 - Train Loss: 0.0513, Train Acc: 0.9864, Val Loss: 0.4741, Val Acc: 0.9138\n",
      "Epoch 26/50 - Train Loss: 0.0604, Train Acc: 0.9836, Val Loss: 0.4054, Val Acc: 0.9124\n",
      "Epoch 27/50 - Train Loss: 0.0396, Train Acc: 0.9893, Val Loss: 0.4357, Val Acc: 0.9037\n",
      "Epoch 28/50 - Train Loss: 0.0289, Train Acc: 0.9918, Val Loss: 0.3947, Val Acc: 0.9124\n",
      "Early stopping triggered.\n",
      "\n",
      "Training MaxViT...\n",
      "Epoch 1/50 - Train Loss: 1.2981, Train Acc: 0.6201, Val Loss: 1.1231, Val Acc: 0.6178\n",
      "Epoch 2/50 - Train Loss: 0.8651, Train Acc: 0.7303, Val Loss: 0.9837, Val Acc: 0.7141\n",
      "Epoch 3/50 - Train Loss: 0.7591, Train Acc: 0.7611, Val Loss: 0.7279, Val Acc: 0.7615\n",
      "Epoch 4/50 - Train Loss: 0.5709, Train Acc: 0.8146, Val Loss: 0.6121, Val Acc: 0.8290\n",
      "Epoch 5/50 - Train Loss: 0.5431, Train Acc: 0.8294, Val Loss: 1.5042, Val Acc: 0.5273\n",
      "Epoch 6/50 - Train Loss: 0.5104, Train Acc: 0.8450, Val Loss: 0.9859, Val Acc: 0.7083\n",
      "Epoch 7/50 - Train Loss: 0.4773, Train Acc: 0.8491, Val Loss: 0.7704, Val Acc: 0.7816\n",
      "Epoch 8/50 - Train Loss: 0.2257, Train Acc: 0.9354, Val Loss: 0.6128, Val Acc: 0.8261\n",
      "Epoch 9/50 - Train Loss: 0.2184, Train Acc: 0.9363, Val Loss: 0.4580, Val Acc: 0.8606\n",
      "Epoch 10/50 - Train Loss: 0.1798, Train Acc: 0.9424, Val Loss: 0.3958, Val Acc: 0.8822\n",
      "Epoch 11/50 - Train Loss: 0.1812, Train Acc: 0.9457, Val Loss: 0.4729, Val Acc: 0.8563\n",
      "Epoch 12/50 - Train Loss: 0.2233, Train Acc: 0.9309, Val Loss: 0.4418, Val Acc: 0.8736\n",
      "Epoch 13/50 - Train Loss: 0.2039, Train Acc: 0.9367, Val Loss: 0.4471, Val Acc: 0.8951\n",
      "Epoch 14/50 - Train Loss: 0.1168, Train Acc: 0.9638, Val Loss: 0.2833, Val Acc: 0.9095\n",
      "Epoch 15/50 - Train Loss: 0.0859, Train Acc: 0.9716, Val Loss: 0.4060, Val Acc: 0.8793\n",
      "Epoch 16/50 - Train Loss: 0.0890, Train Acc: 0.9737, Val Loss: 0.3134, Val Acc: 0.9267\n",
      "Epoch 17/50 - Train Loss: 0.0775, Train Acc: 0.9782, Val Loss: 0.3375, Val Acc: 0.9066\n",
      "Epoch 18/50 - Train Loss: 0.0566, Train Acc: 0.9836, Val Loss: 0.3601, Val Acc: 0.9095\n",
      "Epoch 19/50 - Train Loss: 0.0533, Train Acc: 0.9848, Val Loss: 0.3630, Val Acc: 0.9095\n",
      "Early stopping triggered.\n",
      "\n",
      "Training Time per Model:\n",
      "ConvNeXt-Tiny: 1453.32 seconds (24.22 minutes)\n",
      "EfficientNetV2: 395.76 seconds (6.60 minutes)\n",
      "RegNetY-8GF: 1193.77 seconds (19.90 minutes)\n",
      "MaxViT: 834.63 seconds (13.91 minutes)\n"
     ]
    }
   ],
   "source": [
    "# Store Results\n",
    "results = {}\n",
    "training_times = {}\n",
    "\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "\n",
    "for name, model in models.items():\n",
    "    model.to(device)  # Move model to GPU if available\n",
    "    print(f\"\\nTraining {name}...\")\n",
    "    history, total_time = train_model(model, optimizers[name], train_loader, valid_loader, num_epochs, device)\n",
    "    results[name] = {\"model\": model, \"history\": history}\n",
    "    \n",
    "    # Store the training time for each model in the dictionary\n",
    "    training_times[name] = total_time  # Using model name as the key and storing the training time\n",
    "\n",
    "print(\"\\nTraining Time per Model:\")\n",
    "for name, duration in training_times.items():\n",
    "    print(f\"{name}: {duration:.2f} seconds ({duration/60:.2f} minutes)\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "ca27378e-f357-4a09-91cc-259db407fa4c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a folder to save the plots\n",
    "save_dir = \"E:/Works/12. Plant Diseases Classification/Results/10. Testing Time/4. Testing Time without Metahurestics/Accuracy_Loss_Curves\"\n",
    "os.makedirs(save_dir, exist_ok=True)\n",
    "\n",
    "# Modify plot_metrics to save plots\n",
    "def plot_metrics(history, model_name):\n",
    "    epochs = range(1, len(history[\"train_acc\"]) + 1)  # Fix: Use actual history length\n",
    "    plt.figure(figsize=(12, 5))\n",
    "\n",
    "    # Accuracy Plot\n",
    "    plt.subplot(1, 2, 1)\n",
    "    plt.plot(epochs, history[\"train_acc\"], label=\"Train Accuracy\")\n",
    "    plt.plot(epochs, history[\"valid_acc\"], label=\"Validation Accuracy\")\n",
    "    plt.title(f\"{model_name} Accuracy\")\n",
    "    plt.legend()\n",
    "\n",
    "    # Loss Plot\n",
    "    plt.subplot(1, 2, 2)\n",
    "    plt.plot(epochs, history[\"train_loss\"], label=\"Train Loss\")\n",
    "    plt.plot(epochs, history[\"valid_loss\"], label=\"Validation Loss\")\n",
    "    plt.title(f\"{model_name} Loss\")\n",
    "    plt.legend()\n",
    "\n",
    "    # Save the plot\n",
    "    plt.savefig(os.path.join(save_dir, f\"{model_name}_metrics.png\"))\n",
    "    plt.close()\n",
    "\n",
    "# Plot for each model and save\n",
    "for name, data in results.items():\n",
    "    plot_metrics(data[\"history\"], name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "ac22eaf0-4dfa-4911-b4f2-7b6cb74c3aa8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Classification Report for ConvNeXt-Tiny on Original Test Set:\n",
      "\n",
      "                precision    recall  f1-score   support\n",
      "\n",
      "   A_blk_rot_f     0.3636    0.6667    0.4706         6\n",
      "    A_blk_spot     0.3571    0.5000    0.4167        10\n",
      "    A_e_canker     0.6818    0.8824    0.7692        17\n",
      "  A_gl_lf_spot     0.7692    0.6452    0.7018        31\n",
      "   A_healthy_f     0.7778    0.8235    0.8000        17\n",
      "   A_healthy_l     0.2105    0.2353    0.2222        17\n",
      "     A_m_virus     0.6316    0.6000    0.6154        20\n",
      "Av_alg_lf_spot     0.4706    1.0000    0.6400         8\n",
      "  Av_br_canker     0.9048    0.7600    0.8261        25\n",
      "  Av_healthy_l     0.9231    0.5217    0.6667        23\n",
      "  G_blk_spot_c     0.5833    0.8750    0.7000         8\n",
      "   G_healthy_c     1.0000    0.7647    0.8667        17\n",
      " Kf_bac_canker     0.9677    0.9375    0.9524        32\n",
      "  Kf_healthy_l     0.9643    1.0000    0.9818        27\n",
      "      P_canker     0.6667    0.8000    0.7273        10\n",
      "   P_fr_blight     0.6667    0.3333    0.4444        12\n",
      "   P_healthy_f     0.9412    0.8000    0.8649        20\n",
      "   P_healthy_l     0.7727    0.8500    0.8095        20\n",
      "       P_s_pit     1.0000    0.2857    0.4444         7\n",
      "        P_scab     0.5200    0.6190    0.5652        21\n",
      "\n",
      "      accuracy                         0.7184       348\n",
      "     macro avg     0.7086    0.6950    0.6743       348\n",
      "  weighted avg     0.7580    0.7184    0.7213       348\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "E:\\Works\\12. Plant Diseases Classification\\venv\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1565: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "E:\\Works\\12. Plant Diseases Classification\\venv\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1565: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "E:\\Works\\12. Plant Diseases Classification\\venv\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1565: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "E:\\Works\\12. Plant Diseases Classification\\venv\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1565: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "E:\\Works\\12. Plant Diseases Classification\\venv\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1565: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "E:\\Works\\12. Plant Diseases Classification\\venv\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1565: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Classification Report for ConvNeXt-Tiny on External Test Set:\n",
      "\n",
      "                precision    recall  f1-score   support\n",
      "\n",
      "   A_blk_rot_f     0.4306    0.4921    0.4593        63\n",
      "    A_blk_spot     0.1154    0.4000    0.1791        15\n",
      "    A_e_canker     0.1111    0.0833    0.0952        12\n",
      "  A_gl_lf_spot     0.3077    0.2667    0.2857        15\n",
      "   A_healthy_f     0.8125    0.2955    0.4333        44\n",
      "   A_healthy_l     0.0000    0.0000    0.0000        15\n",
      "     A_m_virus     0.5294    0.2432    0.3333        37\n",
      "Av_alg_lf_spot     0.0385    0.0909    0.0541        11\n",
      "  Av_br_canker     0.2308    0.1579    0.1875        19\n",
      "  Av_healthy_l     0.4706    0.2667    0.3404        30\n",
      "  G_blk_spot_c     0.1111    0.2000    0.1429         5\n",
      "   G_healthy_c     0.9615    0.5882    0.7299        85\n",
      " Kf_bac_canker     0.0000    0.0000    0.0000        14\n",
      "  Kf_healthy_l     0.6667    0.0571    0.1053        35\n",
      "      P_canker     0.2188    0.6364    0.3256        11\n",
      "   P_fr_blight     0.2000    0.5000    0.2857        20\n",
      "   P_healthy_f     0.6667    0.3158    0.4286        19\n",
      "   P_healthy_l     0.0857    0.1579    0.1111        19\n",
      "       P_s_pit     0.0000    0.0000    0.0000        13\n",
      "        P_scab     0.2088    0.5000    0.2946        38\n",
      "\n",
      "      accuracy                         0.3346       520\n",
      "     macro avg     0.3083    0.2626    0.2396       520\n",
      "  weighted avg     0.4679    0.3346    0.3462       520\n",
      "\n",
      "\n",
      "Classification Report for EfficientNetV2 on Original Test Set:\n",
      "\n",
      "                precision    recall  f1-score   support\n",
      "\n",
      "   A_blk_rot_f     1.0000    0.8333    0.9091         6\n",
      "    A_blk_spot     0.6667    0.8000    0.7273        10\n",
      "    A_e_canker     0.8333    0.8824    0.8571        17\n",
      "  A_gl_lf_spot     0.8750    0.9032    0.8889        31\n",
      "   A_healthy_f     1.0000    1.0000    1.0000        17\n",
      "   A_healthy_l     1.0000    0.8235    0.9032        17\n",
      "     A_m_virus     0.9412    0.8000    0.8649        20\n",
      "Av_alg_lf_spot     0.8000    1.0000    0.8889         8\n",
      "  Av_br_canker     0.8929    1.0000    0.9434        25\n",
      "  Av_healthy_l     1.0000    0.7826    0.8780        23\n",
      "  G_blk_spot_c     0.6154    1.0000    0.7619         8\n",
      "   G_healthy_c     1.0000    0.7647    0.8667        17\n",
      " Kf_bac_canker     1.0000    1.0000    1.0000        32\n",
      "  Kf_healthy_l     1.0000    1.0000    1.0000        27\n",
      "      P_canker     0.7692    1.0000    0.8696        10\n",
      "   P_fr_blight     1.0000    0.7500    0.8571        12\n",
      "   P_healthy_f     0.8636    0.9500    0.9048        20\n",
      "   P_healthy_l     0.9500    0.9500    0.9500        20\n",
      "       P_s_pit     0.8333    0.7143    0.7692         7\n",
      "        P_scab     0.9091    0.9524    0.9302        21\n",
      "\n",
      "      accuracy                         0.9080       348\n",
      "     macro avg     0.8975    0.8953    0.8885       348\n",
      "  weighted avg     0.9204    0.9080    0.9087       348\n",
      "\n",
      "\n",
      "Classification Report for EfficientNetV2 on External Test Set:\n",
      "\n",
      "                precision    recall  f1-score   support\n",
      "\n",
      "   A_blk_rot_f     0.7593    0.6508    0.7009        63\n",
      "    A_blk_spot     0.5000    0.8000    0.6154        15\n",
      "    A_e_canker     0.3750    0.5000    0.4286        12\n",
      "  A_gl_lf_spot     0.8333    0.6667    0.7407        15\n",
      "   A_healthy_f     0.8500    0.7727    0.8095        44\n",
      "   A_healthy_l     0.7143    0.3333    0.4545        15\n",
      "     A_m_virus     0.8205    0.8649    0.8421        37\n",
      "Av_alg_lf_spot     0.4167    0.9091    0.5714        11\n",
      "  Av_br_canker     0.7222    0.6842    0.7027        19\n",
      "  Av_healthy_l     0.6190    0.4333    0.5098        30\n",
      "  G_blk_spot_c     0.1250    0.2000    0.1538         5\n",
      "   G_healthy_c     1.0000    0.6235    0.7681        85\n",
      " Kf_bac_canker     0.9091    0.7143    0.8000        14\n",
      "  Kf_healthy_l     1.0000    0.6286    0.7719        35\n",
      "      P_canker     0.1935    0.5455    0.2857        11\n",
      "   P_fr_blight     0.4444    0.8000    0.5714        20\n",
      "   P_healthy_f     0.7083    0.8947    0.7907        19\n",
      "   P_healthy_l     0.3784    0.7368    0.5000        19\n",
      "       P_s_pit     1.0000    0.2308    0.3750        13\n",
      "        P_scab     0.8000    0.8421    0.8205        38\n",
      "\n",
      "      accuracy                         0.6731       520\n",
      "     macro avg     0.6585    0.6416    0.6106       520\n",
      "  weighted avg     0.7617    0.6731    0.6877       520\n",
      "\n",
      "\n",
      "Classification Report for RegNetY-8GF on Original Test Set:\n",
      "\n",
      "                precision    recall  f1-score   support\n",
      "\n",
      "   A_blk_rot_f     1.0000    0.8333    0.9091         6\n",
      "    A_blk_spot     0.7500    0.9000    0.8182        10\n",
      "    A_e_canker     0.8421    0.9412    0.8889        17\n",
      "  A_gl_lf_spot     0.9032    0.9032    0.9032        31\n",
      "   A_healthy_f     0.8889    0.9412    0.9143        17\n",
      "   A_healthy_l     0.8667    0.7647    0.8125        17\n",
      "     A_m_virus     0.9412    0.8000    0.8649        20\n",
      "Av_alg_lf_spot     1.0000    1.0000    1.0000         8\n",
      "  Av_br_canker     1.0000    1.0000    1.0000        25\n",
      "  Av_healthy_l     1.0000    0.9565    0.9778        23\n",
      "  G_blk_spot_c     1.0000    1.0000    1.0000         8\n",
      "   G_healthy_c     1.0000    1.0000    1.0000        17\n",
      " Kf_bac_canker     1.0000    1.0000    1.0000        32\n",
      "  Kf_healthy_l     0.9643    1.0000    0.9818        27\n",
      "      P_canker     0.7143    1.0000    0.8333        10\n",
      "   P_fr_blight     1.0000    0.5833    0.7368        12\n",
      "   P_healthy_f     1.0000    1.0000    1.0000        20\n",
      "   P_healthy_l     0.8571    0.9000    0.8780        20\n",
      "       P_s_pit     0.7500    0.8571    0.8000         7\n",
      "        P_scab     0.9048    0.9048    0.9048        21\n",
      "\n",
      "      accuracy                         0.9253       348\n",
      "     macro avg     0.9191    0.9143    0.9112       348\n",
      "  weighted avg     0.9312    0.9253    0.9245       348\n",
      "\n",
      "\n",
      "Classification Report for RegNetY-8GF on External Test Set:\n",
      "\n",
      "                precision    recall  f1-score   support\n",
      "\n",
      "   A_blk_rot_f     0.8421    0.2540    0.3902        63\n",
      "    A_blk_spot     0.3636    0.8000    0.5000        15\n",
      "    A_e_canker     0.3333    0.5000    0.4000        12\n",
      "  A_gl_lf_spot     0.6429    0.6000    0.6207        15\n",
      "   A_healthy_f     0.6897    0.9091    0.7843        44\n",
      "   A_healthy_l     0.3750    0.2000    0.2609        15\n",
      "     A_m_virus     0.8571    0.8108    0.8333        37\n",
      "Av_alg_lf_spot     0.4000    0.3636    0.3810        11\n",
      "  Av_br_canker     0.4348    0.5263    0.4762        19\n",
      "  Av_healthy_l     0.5517    0.5333    0.5424        30\n",
      "  G_blk_spot_c     0.1250    0.2000    0.1538         5\n",
      "   G_healthy_c     1.0000    0.4000    0.5714        85\n",
      " Kf_bac_canker     0.8462    0.7857    0.8148        14\n",
      "  Kf_healthy_l     1.0000    0.2000    0.3333        35\n",
      "      P_canker     0.1750    0.6364    0.2745        11\n",
      "   P_fr_blight     0.2909    0.8000    0.4267        20\n",
      "   P_healthy_f     0.4500    0.9474    0.6102        19\n",
      "   P_healthy_l     0.2857    0.5263    0.3704        19\n",
      "       P_s_pit     1.0000    0.0769    0.1429        13\n",
      "        P_scab     0.8000    0.8421    0.8205        38\n",
      "\n",
      "      accuracy                         0.5442       520\n",
      "     macro avg     0.5732    0.5456    0.4854       520\n",
      "  weighted avg     0.7051    0.5442    0.5396       520\n",
      "\n",
      "\n",
      "Classification Report for MaxViT on Original Test Set:\n",
      "\n",
      "                precision    recall  f1-score   support\n",
      "\n",
      "   A_blk_rot_f     0.8333    0.8333    0.8333         6\n",
      "    A_blk_spot     0.7500    0.9000    0.8182        10\n",
      "    A_e_canker     1.0000    0.7647    0.8667        17\n",
      "  A_gl_lf_spot     0.8788    0.9355    0.9062        31\n",
      "   A_healthy_f     0.7727    1.0000    0.8718        17\n",
      "   A_healthy_l     0.7222    0.7647    0.7429        17\n",
      "     A_m_virus     0.9375    0.7500    0.8333        20\n",
      "Av_alg_lf_spot     0.8000    1.0000    0.8889         8\n",
      "  Av_br_canker     0.8929    1.0000    0.9434        25\n",
      "  Av_healthy_l     0.9412    0.6957    0.8000        23\n",
      "  G_blk_spot_c     1.0000    1.0000    1.0000         8\n",
      "   G_healthy_c     1.0000    1.0000    1.0000        17\n",
      " Kf_bac_canker     1.0000    1.0000    1.0000        32\n",
      "  Kf_healthy_l     1.0000    1.0000    1.0000        27\n",
      "      P_canker     0.5882    1.0000    0.7407        10\n",
      "   P_fr_blight     1.0000    0.4167    0.5882        12\n",
      "   P_healthy_f     0.8696    1.0000    0.9302        20\n",
      "   P_healthy_l     0.9524    1.0000    0.9756        20\n",
      "       P_s_pit     1.0000    0.4286    0.6000         7\n",
      "        P_scab     1.0000    0.9524    0.9756        21\n",
      "\n",
      "      accuracy                         0.8966       348\n",
      "     macro avg     0.8969    0.8721    0.8658       348\n",
      "  weighted avg     0.9126    0.8966    0.8922       348\n",
      "\n",
      "\n",
      "Classification Report for MaxViT on External Test Set:\n",
      "\n",
      "                precision    recall  f1-score   support\n",
      "\n",
      "   A_blk_rot_f     0.8235    0.6667    0.7368        63\n",
      "    A_blk_spot     0.4211    0.5333    0.4706        15\n",
      "    A_e_canker     1.0000    0.1667    0.2857        12\n",
      "  A_gl_lf_spot     0.9091    0.6667    0.7692        15\n",
      "   A_healthy_f     0.7059    0.8182    0.7579        44\n",
      "   A_healthy_l     0.3333    0.1333    0.1905        15\n",
      "     A_m_virus     0.8649    0.8649    0.8649        37\n",
      "Av_alg_lf_spot     0.4000    0.7273    0.5161        11\n",
      "  Av_br_canker     0.7000    0.7368    0.7179        19\n",
      "  Av_healthy_l     0.6190    0.4333    0.5098        30\n",
      "  G_blk_spot_c     1.0000    0.2000    0.3333         5\n",
      "   G_healthy_c     1.0000    0.8118    0.8961        85\n",
      " Kf_bac_canker     0.7500    0.6429    0.6923        14\n",
      "  Kf_healthy_l     1.0000    0.4286    0.6000        35\n",
      "      P_canker     0.1897    1.0000    0.3188        11\n",
      "   P_fr_blight     0.7333    0.5500    0.6286        20\n",
      "   P_healthy_f     0.7500    0.9474    0.8372        19\n",
      "   P_healthy_l     0.3611    0.6842    0.4727        19\n",
      "       P_s_pit     1.0000    0.3077    0.4706        13\n",
      "        P_scab     0.6875    0.8684    0.7674        38\n",
      "\n",
      "      accuracy                         0.6750       520\n",
      "     macro avg     0.7124    0.6094    0.5918       520\n",
      "  weighted avg     0.7705    0.6750    0.6847       520\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Function to evaluate model and save classification report\n",
    "def evaluate_model(model, test_loader, model_name, dataset_name):\n",
    "    model.eval()\n",
    "    y_true, y_pred = [], []\n",
    "    \n",
    "    start_time = time.time()  # Start timing\n",
    "\n",
    "    with torch.no_grad():\n",
    "        for images, labels in test_loader:\n",
    "            images, labels = images.to(device), labels.to(device)\n",
    "            outputs = model(images)\n",
    "            _, preds = torch.max(outputs, 1)\n",
    "            y_true.extend(labels.cpu().numpy())\n",
    "            y_pred.extend(preds.cpu().numpy())\n",
    "\n",
    "    end_time = time.time()  # End timing\n",
    "    testing_time = round((end_time - start_time) * 1000, 2)  # Convert to milliseconds\n",
    "\n",
    "    report = classification_report(y_true, y_pred, target_names=class_names, digits=4, output_dict=True)\n",
    "    print(f\"\\nClassification Report for {model_name} on {dataset_name}:\\n\")\n",
    "    print(classification_report(y_true, y_pred, target_names=class_names, digits=4))\n",
    "    \n",
    "    return y_true, y_pred, report, testing_time\n",
    "\n",
    "    \n",
    "\n",
    "# Evaluate each model on both test sets and store results\n",
    "model_reports = {}\n",
    "predictions = {}\n",
    "testing_times = {}\n",
    "\n",
    "for mh_name, mh_results in results.items():  # Iterate over models\n",
    "    model = mh_results[\"model\"]  # Directly retrieve the model from the 'model' key in mh_results\n",
    "\n",
    "    # Evaluate on Original Test Set\n",
    "    y_true, y_pred, report, test_time = evaluate_model(model, test_loader, f\"{mh_name}\", \"Original Test Set\")\n",
    "    model_reports[f\"{mh_name}_Test\"] = report\n",
    "    predictions[f\"{mh_name}_Test\"] = (y_true, y_pred)\n",
    "    testing_times[f\"{mh_name}_Test\"] = test_time\n",
    "\n",
    "    # Evaluate on External Test Set\n",
    "    y_true, y_pred, report, test_time = evaluate_model(model, external_test_loader, f\"{mh_name}\", \"External Test Set\")\n",
    "    model_reports[f\"{mh_name}_External_Test\"] = report\n",
    "    predictions[f\"{mh_name}_External_Test\"] = (y_true, y_pred)\n",
    "    testing_times[f\"{mh_name}_External_Test\"] = test_time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "89a133e3-27f8-4177-b8f3-06a76347e5b9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a folder to save the confusion matrices\n",
    "cm_save_dir = \"E:/Works/12. Plant Diseases Classification/Results/10. Testing Time/4. Testing Time without Metahurestics/Confusion Matrix\"\n",
    "os.makedirs(cm_save_dir, exist_ok=True)\n",
    "\n",
    "# Modify plot_confusion_matrix to save plots\n",
    "def plot_confusion_matrix(y_true, y_pred, classes, model_name, dataset_name):\n",
    "    cm = confusion_matrix(y_true, y_pred)\n",
    "    plt.figure(figsize=(10, 7))\n",
    "    sns.heatmap(cm, annot=True, fmt=\"d\", xticklabels=classes, yticklabels=classes, cmap=\"Blues\")\n",
    "    plt.xlabel(\"Predicted Label\")\n",
    "    plt.ylabel(\"True Label\")\n",
    "    plt.title(f\"Confusion Matrix - {model_name} ({dataset_name})\")\n",
    "\n",
    "    # Save the plot with dataset name included\n",
    "    filename = f\"{model_name}_{dataset_name.replace(' ', '_')}_confusion_matrix.png\"\n",
    "    plt.savefig(os.path.join(cm_save_dir, filename))\n",
    "    plt.close()\n",
    "\n",
    "# Generate and save confusion matrices for both test sets\n",
    "for name, data in results.items():\n",
    "    # Confusion Matrix for Original Test Set\n",
    "    y_true, y_pred = predictions[f\"{name}_Test\"]\n",
    "    plot_confusion_matrix(y_true, y_pred, class_names, name, \"Original_Test_Set\")\n",
    "\n",
    "    # Confusion Matrix for External Test Set\n",
    "    y_true, y_pred = predictions[f\"{name}_External_Test\"]\n",
    "    plot_confusion_matrix(y_true, y_pred, class_names, name, \"External_Test_Set\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "fcc199c6-f675-4daa-bcb0-cce54e031600",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a folder to save the ROC curves\n",
    "roc_save_dir = \"E:/Works/12. Plant Diseases Classification/Results/10. Testing Time/4. Testing Time without Metahurestics/ROC Curves\"\n",
    "os.makedirs(roc_save_dir, exist_ok=True)\n",
    "\n",
    "# Modify compute_auc to save plots\n",
    "def compute_auc(model, test_loader, model_name, dataset_name):\n",
    "    model.eval()\n",
    "    y_true, y_scores = [], []\n",
    "\n",
    "    with torch.no_grad():\n",
    "        for images, labels in test_loader:\n",
    "            images, labels = images.to(device), labels.to(device)\n",
    "            outputs = model(images)\n",
    "            probabilities = torch.nn.functional.softmax(outputs, dim=1)\n",
    "\n",
    "            y_true.extend(labels.cpu().numpy())\n",
    "            y_scores.extend(probabilities.cpu().numpy())\n",
    "\n",
    "    y_true = np.array(y_true)\n",
    "    y_scores = np.array(y_scores)\n",
    "\n",
    "    auc_scores = {}\n",
    "    plt.figure(figsize=(10, 7))\n",
    "\n",
    "    for i in range(num_classes):\n",
    "        fpr, tpr, _ = roc_curve(y_true == i, y_scores[:, i])\n",
    "        roc_auc = auc(fpr, tpr)\n",
    "        auc_scores[class_names[i]] = round(roc_auc, 4)  # Round AUC to 4 decimal points\n",
    "        plt.plot(fpr, tpr, label=f\"{model_name} (Class {class_names[i]}) AUC = {roc_auc:.4f}\")\n",
    "\n",
    "    plt.plot([0, 1], [0, 1], \"k--\")  # Diagonal line\n",
    "    plt.xlabel(\"False Positive Rate\")\n",
    "    plt.ylabel(\"True Positive Rate\")\n",
    "    plt.title(f\"ROC Curve - {model_name} ({dataset_name})\")\n",
    "    plt.legend(loc=\"lower right\")\n",
    "\n",
    "    # Save the plot with dataset name included\n",
    "    filename = f\"{model_name}_{dataset_name.replace(' ', '_')}_roc_curve.png\"\n",
    "    plt.savefig(os.path.join(roc_save_dir, filename))\n",
    "    plt.close()\n",
    "\n",
    "    return auc_scores\n",
    "\n",
    "# Compute and store AUC scores for each model and both test sets\n",
    "auc_results = {}\n",
    "\n",
    "for name, data in results.items():\n",
    "    # AUC for Original Test Set\n",
    "    auc_scores_test = compute_auc(data[\"model\"], test_loader, name, \"Original_Test_Set\")\n",
    "    auc_results[f\"{name}_Test\"] = auc_scores_test\n",
    "\n",
    "    # AUC for External Test Set\n",
    "    auc_scores_external_test = compute_auc(data[\"model\"], external_test_loader, name, \"External_Test_Set\")\n",
    "    auc_results[f\"{name}_External_Test\"] = auc_scores_external_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "affcdf21-7ec0-436b-b626-61ff61b2d2b3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Model Performance Comparison for Both Test Sets:\n",
      "\n",
      "                     Model            Dataset  Accuracy (%)  Precision (%)  \\\n",
      "0            ConvNeXt-Tiny  Original Test Set         71.84          70.86   \n",
      "1   ConvNeXt-Tiny_External  External Test Set         33.46          30.83   \n",
      "2           EfficientNetV2  Original Test Set         90.80          89.75   \n",
      "3  EfficientNetV2_External  External Test Set         67.31          65.85   \n",
      "4              RegNetY-8GF  Original Test Set         92.53          91.91   \n",
      "5     RegNetY-8GF_External  External Test Set         54.42          57.32   \n",
      "6                   MaxViT  Original Test Set         89.66          89.69   \n",
      "7          MaxViT_External  External Test Set         67.50          71.24   \n",
      "\n",
      "   Recall (%)  F1-Score (%)  Mean AUC (%)  Training Time (mins)  \\\n",
      "0       69.50         67.43         98.05                 24.22   \n",
      "1       26.26         23.96         84.82                  0.00   \n",
      "2       89.53         88.85         99.76                  6.60   \n",
      "3       64.16         61.06         96.95                  0.00   \n",
      "4       91.43         91.12         99.84                 19.90   \n",
      "5       54.56         48.54         94.03                  0.00   \n",
      "6       87.21         86.58         99.84                 13.91   \n",
      "7       60.94         59.18         95.79                  0.00   \n",
      "\n",
      "   Testing Time (ms)  \n",
      "0            1060.80  \n",
      "1            1581.57  \n",
      "2             987.73  \n",
      "3            1359.00  \n",
      "4            1695.79  \n",
      "5            2531.48  \n",
      "6            1853.70  \n",
      "7            2719.63  \n"
     ]
    }
   ],
   "source": [
    "# Extract relevant metrics separately for both test sets\n",
    "model_names = []\n",
    "dataset_types = []\n",
    "accuracy_scores = []\n",
    "precision_scores = []\n",
    "recall_scores = []\n",
    "f1_scores = []\n",
    "auc_mean_scores = []\n",
    "training_times_list = []  # Store training times in this list\n",
    "testing_time_values = []\n",
    "\n",
    "for name, report in model_reports.items():\n",
    "    dataset_type = \"External Test Set\" if \"External_Test\" in name else \"Original Test Set\"\n",
    "    base_name = name.replace(\"_Test\", \"\").replace(\"_External_Test\", \"\")\n",
    "\n",
    "    model_names.append(base_name)\n",
    "    dataset_types.append(dataset_type)\n",
    "    \n",
    "    accuracy_scores.append(round(report[\"accuracy\"] * 100, 2))  # Convert to percentage\n",
    "    precision_scores.append(round(report[\"macro avg\"][\"precision\"] * 100, 2))\n",
    "    recall_scores.append(round(report[\"macro avg\"][\"recall\"] * 100, 2))\n",
    "    f1_scores.append(round(report[\"macro avg\"][\"f1-score\"] * 100, 2))\n",
    "    \n",
    "    # Compute mean AUC across all classes (ensure auc_results is correctly defined and used)\n",
    "    mean_auc = np.mean(list(auc_results.get(name, {}).values()))  # Use .get() to avoid errors\n",
    "    auc_mean_scores.append(round(mean_auc * 100, 2))\n",
    "\n",
    "    # Correct way to extract training time from training_times dictionary\n",
    "    training_time = training_times.get(base_name, 0)  # .get() works now because training_times is a dictionary\n",
    "    training_times_list.append(round(training_time / 60, 2))  # Store in list, convert to minutes\n",
    "\n",
    "    # Extract testing time from testing_times dictionary\n",
    "    testing_time = testing_times.get(name, 0)  # Use .get() to safely retrieve testing time\n",
    "    testing_time_values.append(testing_time)  # Store in milliseconds\n",
    "\n",
    "# Create DataFrame with the extracted metrics\n",
    "df_metrics = pd.DataFrame({\n",
    "    \"Model\": model_names,\n",
    "    \"Dataset\": dataset_types,\n",
    "    \"Accuracy (%)\": accuracy_scores,\n",
    "    \"Precision (%)\": precision_scores,\n",
    "    \"Recall (%)\": recall_scores,\n",
    "    \"F1-Score (%)\": f1_scores,\n",
    "    \"Mean AUC (%)\": auc_mean_scores,\n",
    "    \"Training Time (mins)\": training_times_list,\n",
    "    \"Testing Time (ms)\": testing_time_values\n",
    "})\n",
    "\n",
    "# Display the table\n",
    "print(\"\\nModel Performance Comparison for Both Test Sets:\\n\")\n",
    "print(df_metrics)\n",
    "\n",
    "# Save DataFrame to CSV\n",
    "csv_path = \"E:/Works/12. Plant Diseases Classification/Results/10. Testing Time/4. Testing Time without Metahurestics/model_performance_metrics_without_metahurestics.csv\"\n",
    "df_metrics.to_csv(csv_path, index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0e5c632c-feaa-4f63-9a8d-62764edd5ef1",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
